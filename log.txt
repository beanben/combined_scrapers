2023-10-29 19:59 - INFO: Enabled addons:
[]
2023-10-29 19:59 - WARNING: /Users/benoitfesquet/.local/share/virtualenvs/combined_scrapers-HMO1jZc6/lib/python3.9/site-packages/scrapy/utils/request.py:254: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.

It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.

See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.
  return cls(crawler)

2023-10-29 19:59 - INFO: Telnet Password: 86f1ed6aece21fc8
2023-10-29 19:59 - INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2023-10-29 19:59 - INFO: Overridden settings:
{'BOT_NAME': 'operators',
 'LOG_DATEFORMAT': '%Y-%m-%d %H:%M',
 'LOG_FILE': 'log.txt',
 'LOG_FORMAT': '%(asctime)s - %(levelname)s: %(message)s',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'operators.spiders',
 'RETRY_HTTP_CODES': [403, 524],
 'RETRY_TIMES': 5,
 'SPIDER_MODULES': ['operators.spiders']}
2023-10-29 20:01 - CRITICAL: Unhandled error in Deferred:
2023-10-29 20:01 - CRITICAL: 
Traceback (most recent call last):
  File "/Users/benoitfesquet/Dev/scrapy/combined_scrapers/operators/all_spiders.py", line 54, in crawl
    yield runner.crawl(UniteSpider)
  File "/Users/benoitfesquet/.local/share/virtualenvs/combined_scrapers-HMO1jZc6/lib/python3.9/site-packages/twisted/internet/defer.py", line 1697, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/benoitfesquet/.local/share/virtualenvs/combined_scrapers-HMO1jZc6/lib/python3.9/site-packages/scrapy/crawler.py", line 158, in crawl
    self.engine = self._create_engine()
  File "/Users/benoitfesquet/.local/share/virtualenvs/combined_scrapers-HMO1jZc6/lib/python3.9/site-packages/scrapy/crawler.py", line 172, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/Users/benoitfesquet/.local/share/virtualenvs/combined_scrapers-HMO1jZc6/lib/python3.9/site-packages/scrapy/core/engine.py", line 99, in __init__
    self.downloader: Downloader = downloader_cls(crawler)
  File "/Users/benoitfesquet/.local/share/virtualenvs/combined_scrapers-HMO1jZc6/lib/python3.9/site-packages/scrapy/core/downloader/__init__.py", line 97, in __init__
    DownloaderMiddlewareManager.from_crawler(crawler)
  File "/Users/benoitfesquet/.local/share/virtualenvs/combined_scrapers-HMO1jZc6/lib/python3.9/site-packages/scrapy/middleware.py", line 90, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/Users/benoitfesquet/.local/share/virtualenvs/combined_scrapers-HMO1jZc6/lib/python3.9/site-packages/scrapy/middleware.py", line 67, in from_settings
    mw = create_instance(mwcls, settings, crawler)
  File "/Users/benoitfesquet/.local/share/virtualenvs/combined_scrapers-HMO1jZc6/lib/python3.9/site-packages/scrapy/utils/misc.py", line 188, in create_instance
    instance = objcls.from_crawler(crawler, *args, **kwargs)
  File "/Users/benoitfesquet/.local/share/virtualenvs/combined_scrapers-HMO1jZc6/lib/python3.9/site-packages/random_useragent.py", line 41, in from_crawler
    obj = cls(crawler.settings)
  File "/Users/benoitfesquet/.local/share/virtualenvs/combined_scrapers-HMO1jZc6/lib/python3.9/site-packages/random_useragent.py", line 36, in __init__
    with open(user_agent_list_file, 'r') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'user-agent.txt'
